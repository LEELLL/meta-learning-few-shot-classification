{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_miniImagenet_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirandou/meta-learning-few-shot-classification/blob/master/baseline_miniImagenet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmx3jbv530kk",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHl-HKk_3Mug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmPXVo13jhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhsb8Cnf3lSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llgTurVolX7t",
        "colab_type": "code",
        "outputId": "e29f14b8-08c6-4d56-cd9d-28e458000366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa-jE56wS-0V",
        "colab_type": "text"
      },
      "source": [
        "For Saghar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtErM4-bcDde",
        "colab_type": "code",
        "outputId": "0fafb583-68a4-48a8-cd77-b97b23669abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "cd 'drive/My Drive/ML project'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML project\n",
            "[Errno 2] No such file or directory: 'drive/My Drive/ML project'\n",
            "/content/drive/My Drive/ML project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNUFhy1eTBOI",
        "colab_type": "text"
      },
      "source": [
        "For Others:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "918bc141-4543-40b5-92f2-14fafb94c41a",
        "id": "hzifRS-_TEVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cd '/content/drive/My Drive/ML project'"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML project\n",
            "/content/drive/My Drive/ML project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_x4IPkk_ZWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import Sampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9vzezXdTWyd",
        "colab_type": "text"
      },
      "source": [
        "# Getting data folders\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz0rJ5ITqWrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mini_imagenet_folders():\n",
        "    train_folder = 'datas/miniImagenet/train'\n",
        "    test_folder = 'datas/miniImagenet/test'                ##val?\n",
        "    val_folder = 'datas/miniImagenet/val'\n",
        "\n",
        "    metatrain_folders = [os.path.join(train_folder, label) \\\n",
        "                for label in os.listdir(train_folder) \\\n",
        "                if os.path.isdir(os.path.join(train_folder, label)) \\\n",
        "                ]\n",
        "    metatest_folders = [os.path.join(test_folder, label) \\\n",
        "                for label in os.listdir(test_folder) \\\n",
        "                if os.path.isdir(os.path.join(test_folder, label)) \\\n",
        "                ]\n",
        "    metaval_folders = [os.path.join(val_folder, label) \\\n",
        "                for label in os.listdir(val_folder) \\\n",
        "                if os.path.isdir(os.path.join(val_folder, label)) \\\n",
        "                ]\n",
        "\n",
        "    random.seed(1)\n",
        "    random.shuffle(metatrain_folders)\n",
        "    random.shuffle(metatest_folders)\n",
        "    random.shuffle(metaval_folders)\n",
        "\n",
        "    return metatrain_folders,metatest_folders, metaval_folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KX09XQKALfM",
        "colab_type": "code",
        "outputId": "9cf981ac-f573-4775-894a-2ea2dfcbf3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abolfazl-omniglot_test.ipynb\n",
            "baseline_miniImagenet_train_15way-5shot.ipynb\n",
            "baseline_miniImagenet_train.ipynb\n",
            "\u001b[0m\u001b[01;34mdatas\u001b[0m/\n",
            "\u001b[01;34mminiimagenet\u001b[0m/\n",
            "miniImagenet_test.ipynb\n",
            "miniImagenet_train.ipynb\n",
            "\u001b[01;34momniglot\u001b[0m/\n",
            "omniglot_test.ipynb\n",
            "omniglot_train.ipynb\n",
            "resnet18_miniImagenet_train.ipynb\n",
            "Sedi_resnet_miniImagenet_train.ipynb\n",
            "Abolfazl-omniglot_test.ipynb\n",
            "baseline_miniImagenet_train_15way-5shot.ipynb\n",
            "baseline_miniImagenet_train.ipynb\n",
            "\u001b[0m\u001b[01;34mdatas\u001b[0m/\n",
            "\u001b[01;34mminiimagenet\u001b[0m/\n",
            "miniImagenet_test.ipynb\n",
            "miniImagenet_train.ipynb\n",
            "\u001b[01;34momniglot\u001b[0m/\n",
            "omniglot_test.ipynb\n",
            "omniglot_train.ipynb\n",
            "resnet18_miniImagenet_train.ipynb\n",
            "Sedi_resnet_miniImagenet_train.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7M2Orp_xog",
        "colab_type": "code",
        "outputId": "ee9bd34a-2f10-4f88-f3fa-134aba282473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Step 1: init data folders\n",
        "print(\"init data folders\")\n",
        "# init character folders for dataset construction\n",
        "metatrain_folders,metatest_folders,metaval_folders = mini_imagenet_folders()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init data folders\n",
            "init data folders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u2u2IS4Tk41",
        "colab_type": "text"
      },
      "source": [
        "#Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJeVI7wWAmSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import scipy as sp\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "FEATURE_DIM = 64\n",
        "RELATION_DIM = 8\n",
        "CLASS_NUM = 5\n",
        "SAMPLE_NUM_PER_CLASS = 5   #1\n",
        "BATCH_NUM_PER_CLASS = 10   #15\n",
        "EPISODE = 1000\n",
        "TEST_EPISODE = 20\n",
        "LEARNING_RATE = 0.001\n",
        "GPU = 0\n",
        "HIDDEN_UNIT = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJgHS4bxTv6m",
        "colab_type": "text"
      },
      "source": [
        "#Defining the Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH3-0uO3CzXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(3,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        #out = out.view(out.size(0),-1)\n",
        "        return out # 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQ5kfkvDHtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RelationNetwork(nn.Module):\n",
        "    \"\"\"docstring for RelationNetwork\"\"\"\n",
        "    def __init__(self,input_size,hidden_size):\n",
        "        super(RelationNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(64*2,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.fc1 = nn.Linear(input_size*3*3,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = torch.sigmoid(self.fc2(out))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8TP0r34aGCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        n = m.weight.size(1)\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        m.bias.data = torch.ones(m.bias.data.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYagIyND2BX",
        "colab_type": "code",
        "outputId": "c25ab91c-a46f-4a54-de1c-cc128e45e6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# Step 2: init neural networks\n",
        "print(\"init neural networks\")\n",
        "\n",
        "feature_encoder = CNNEncoder()\n",
        "relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
        "\n",
        "feature_encoder.apply(weights_init)\n",
        "relation_network.apply(weights_init)\n",
        "\n",
        "feature_encoder.cuda(GPU)\n",
        "relation_network.cuda(GPU)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelationNetwork(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "text": [
            "init neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelationNetwork(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkpjFwj_T7n2",
        "colab_type": "text"
      },
      "source": [
        "#Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuwctmD2q8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=LEARNING_RATE)\n",
        "feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
        "relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
        "relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhEQlGhyEOzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if os.path.exists(str(\"miniimagenet/models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "#    feature_encoder.load_state_dict(torch.load(str(\"miniimagenet/models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "#    print(\"load feature encoder success\")\n",
        "#if os.path.exists(str(\"miniimagenet/models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "#    relation_network.load_state_dict(torch.load(str(\"miniimagenet/models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "#    print(\"load relation network success\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y85slNVbDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_confidence_interval(data, confidence=0.95):\n",
        "    a = 1.0*np.array(data)\n",
        "    n = len(a)\n",
        "    m, se = np.mean(a), scipy.stats.sem(a)\n",
        "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
        "    return m,h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smn-9W6T-35",
        "colab_type": "text"
      },
      "source": [
        "#Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw9uNk3cFhrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Rotate(object):\n",
        "    def __init__(self, angle):\n",
        "        self.angle = angle\n",
        "    def __call__(self, x, mode=\"reflect\"):\n",
        "        x = x.rotate(self.angle)\n",
        "        return x\n",
        "\n",
        "class MiniImagenetTask(object):\n",
        "\n",
        "    def __init__(self, character_folders, num_classes, train_num,test_num):\n",
        "\n",
        "        self.character_folders = character_folders\n",
        "        self.num_classes = num_classes\n",
        "        self.train_num = train_num\n",
        "        self.test_num = test_num\n",
        "\n",
        "        class_folders = random.sample(self.character_folders,self.num_classes)\n",
        "        labels = np.array(range(len(class_folders)))\n",
        "        labels = dict(zip(class_folders, labels))\n",
        "        samples = dict()\n",
        "\n",
        "        self.train_roots = []\n",
        "        self.test_roots = []\n",
        "        for c in class_folders:\n",
        "\n",
        "            temp = [os.path.join(c, x) for x in os.listdir(c)]\n",
        "            samples[c] = random.sample(temp, len(temp))\n",
        "            random.shuffle(samples[c])\n",
        "\n",
        "            self.train_roots += samples[c][:train_num]\n",
        "            self.test_roots += samples[c][train_num:train_num+test_num]\n",
        "\n",
        "        self.train_labels = [labels[self.get_class(x)] for x in self.train_roots]\n",
        "        self.test_labels = [labels[self.get_class(x)] for x in self.test_roots]\n",
        "\n",
        "    def get_class(self, sample):\n",
        "        return os.path.join(*sample.split('/')[:-1])\n",
        "\n",
        "class FewShotDataset(Dataset):\n",
        "\n",
        "    def __init__(self, task, split='train', transform=None, target_transform=None):\n",
        "        self.transform = transform # Torch operations on the input image\n",
        "        self.target_transform = target_transform\n",
        "        self.task = task\n",
        "        self.split = split\n",
        "        self.image_roots = self.task.train_roots if self.split == 'train' else self.task.test_roots\n",
        "        self.labels = self.task.train_labels if self.split == 'train' else self.task.test_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_roots)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raise NotImplementedError(\"This is an abstract class. Subclass this class for your particular dataset.\")\n",
        "\n",
        "class MiniImagenet(FewShotDataset):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MiniImagenet, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_root = self.image_roots[idx]\n",
        "        image = Image.open(image_root)\n",
        "        image = image.convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class ClassBalancedSampler(Sampler):\n",
        "    ''' Samples 'num_inst' examples each from 'num_cl' pools\n",
        "        of examples of size 'num_per_class' '''\n",
        "\n",
        "    def __init__(self, num_cl, num_inst,shuffle=True):\n",
        "\n",
        "        self.num_cl = num_cl\n",
        "        self.num_inst = num_inst\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # return a single list of indices, assuming that items will be grouped by class\n",
        "        if self.shuffle:\n",
        "            batches = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)] for j in range(self.num_cl)]\n",
        "        else:\n",
        "            batches = [[i+j*self.num_inst for i in range(self.num_inst)] for j in range(self.num_cl)]\n",
        "        batches = [[batches[j][i] for j in range(self.num_cl)] for i in range(self.num_inst)]\n",
        "\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batches)\n",
        "            for sublist in batches:\n",
        "                   random.shuffle(sublist)\n",
        "        batches = [item for sublist in batches for item in sublist]\n",
        "        return iter(batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "class ClassBalancedSamplerOld(Sampler):\n",
        "    ''' Samples 'num_inst' examples each from 'num_cl' pools\n",
        "        of examples of size 'num_per_class' '''\n",
        "\n",
        "    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n",
        "        self.num_per_class = num_per_class\n",
        "        self.num_cl = num_cl\n",
        "        self.num_inst = num_inst\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # return a single list of indices, assuming that items will be grouped by class\n",
        "        if self.shuffle:\n",
        "            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
        "        else:\n",
        "            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
        "        batch = [item for sublist in batch for item in sublist]\n",
        "\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batch)\n",
        "        return iter(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "\n",
        "def get_mini_imagenet_data_loader(task, num_per_class=1, split='train',shuffle = False):\n",
        "    normalize = transforms.Normalize(mean=[0.92206, 0.92206, 0.92206], std=[0.08426, 0.08426, 0.08426])\n",
        "\n",
        "    dataset = MiniImagenet(task,split=split,transform=transforms.Compose([transforms.ToTensor(),normalize]))\n",
        "    if split == 'train':\n",
        "        sampler = ClassBalancedSamplerOld(num_per_class,task.num_classes, task.train_num,shuffle=shuffle)\n",
        "\n",
        "    else:\n",
        "        sampler = ClassBalancedSampler(task.num_classes, task.test_num,shuffle=shuffle)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=num_per_class*task.num_classes, sampler=sampler)\n",
        "    return loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4pNmvd8UCzi",
        "colab_type": "text"
      },
      "source": [
        "#5way-5shot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EazfPJogFFkh",
        "colab_type": "code",
        "outputId": "3f93d8ed-f965-4317-eca9-18dacfd1b668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Step 3: build graph\n",
        "print(\"Training...\")\n",
        "TEST_EPISODE = 20\n",
        "last_accuracy = 0.0\n",
        "\n",
        "for episode in range(EPISODE):\n",
        "    #print(episode)\n",
        "\n",
        "    # init dataset\n",
        "    # sample_dataloader is to obtain previous samples for compare\n",
        "    # batch_dataloader is to batch samples for training\n",
        "    task = MiniImagenetTask(metatest_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "    sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "    batch_dataloader = get_mini_imagenet_data_loader(task,num_per_class=BATCH_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
        "\n",
        "    # sample datas\n",
        "    samples,sample_labels = sample_dataloader.__iter__().next() #25*3*84*84\n",
        "    batches,batch_labels = batch_dataloader.__iter__().next()\n",
        "\n",
        "    # calculate features\n",
        "    sample_features = feature_encoder(Variable(samples).cuda(GPU)) # 25*64*19*19\n",
        "    sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "    sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "    batch_features = feature_encoder(Variable(batches).cuda(GPU)) # 20x64*5*5\n",
        "\n",
        "    # calculate relations\n",
        "    # each batch sample link to every samples to calculate relations\n",
        "    # to form a 100x128 matrix for relation network\n",
        "    sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
        "    relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "    relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "    mse = nn.MSELoss().cuda(GPU)\n",
        "    one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1).cuda(GPU))\n",
        "    loss = mse(relations,one_hot_labels)\n",
        "\n",
        "\n",
        "    # training\n",
        "\n",
        "    feature_encoder.zero_grad()\n",
        "    relation_network.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(),0.5)\n",
        "    torch.nn.utils.clip_grad_norm_(relation_network.parameters(),0.5)\n",
        "\n",
        "    feature_encoder_optim.step()\n",
        "    relation_network_optim.step()\n",
        "\n",
        "    feature_encoder_scheduler.step(episode)\n",
        "    relation_network_scheduler.step(episode)\n",
        "\n",
        "\n",
        "    if (episode+1)%100 == 0:\n",
        "        print(loss.item())\n",
        "\n",
        "    if (episode+1)%1000 == 0:\n",
        "\n",
        "        # test\n",
        "        print(\"Testing...\")\n",
        "        accuracies = []\n",
        "        for i in range(TEST_EPISODE):\n",
        "            total_rewards = 0\n",
        "            counter = 0     #remove\n",
        "            task = MiniImagenetTask(metaval_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "            sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "            num_per_class = 5   #3\n",
        "            test_dataloader = get_mini_imagenet_data_loader(task,num_per_class=num_per_class,split=\"test\",shuffle=False)\n",
        "\n",
        "            sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
        "            for test_images,test_labels in test_dataloader:\n",
        "                batch_size = test_labels.shape[0]\n",
        "                # calculate features\n",
        "                sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
        "                sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "                sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "                test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
        "\n",
        "                # calculate relations\n",
        "                # each batch sample link to every samples to calculate relations\n",
        "                # to form a 100x128 matrix for relation network\n",
        "                sample_features_ext = sample_features.unsqueeze(0).repeat(batch_size,1,1,1,1)\n",
        "\n",
        "                test_features_ext = test_features.unsqueeze(0).repeat(1*CLASS_NUM,1,1,1,1)\n",
        "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
        "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "                _,predict_labels = torch.max(relations.data,1)\n",
        "\n",
        "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(batch_size)]\n",
        "\n",
        "                total_rewards += np.sum(rewards)\n",
        "                counter +=batch_size      #remove\n",
        "\n",
        "\n",
        "            accuracy = total_rewards/1.0/CLASS_NUM/BATCH_NUM_PER_CLASS\n",
        "            #accuracy = total_rewards/1.0/counter\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "        test_accuracy,h = mean_confidence_interval(accuracies)\n",
        "\n",
        "        print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
        "\n",
        "        if test_accuracy > last_accuracy:\n",
        "\n",
        "            # save networks\n",
        "            #torch.save(feature_encoder.state_dict(),str(\"miniimagenet/models/new/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "            #torch.save(relation_network.state_dict(),str(\"miniimagenet/models/new/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "\n",
        "            #print(\"save networks for episode:\",episode)\n",
        "            print(\"better network for episode:\" ,episode)\n",
        "            last_accuracy = test_accuracy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "0.1586916446685791\n",
            "0.14670328795909882\n",
            "0.14058363437652588\n",
            "0.1506078690290451\n",
            "0.14937527477741241\n",
            "0.10397420823574066\n",
            "0.11126196384429932\n",
            "0.12347830832004547\n",
            "0.12104904651641846\n",
            "0.13889151811599731\n",
            "Testing...\n",
            "test accuracy: 0.4010000000000001 h: 0.04468186467502009\n",
            "better network for episode: 999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_6hSkpU58G",
        "colab_type": "text"
      },
      "source": [
        "#5way-1shot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c25ab91c-a46f-4a54-de1c-cc128e45e6dd",
        "id": "uYxah47dN179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# Step 2: init neural networks\n",
        "print(\"init neural networks\")\n",
        "\n",
        "feature_encoder = CNNEncoder()\n",
        "relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
        "\n",
        "feature_encoder.apply(weights_init)\n",
        "relation_network.apply(weights_init)\n",
        "\n",
        "feature_encoder.cuda(GPU)\n",
        "relation_network.cuda(GPU)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelationNetwork(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "text": [
            "init neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelationNetwork(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1OjE-DkUYOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bcfc8a-1f3e-4290-924d-966a4feab2e3"
      },
      "source": [
        "# Step 3: build graph\n",
        "print(\"Training...\")\n",
        "# Hyper Parameters\n",
        "CLASS_NUM = 5\n",
        "SAMPLE_NUM_PER_CLASS = 1   #5\n",
        "BATCH_NUM_PER_CLASS = 10   #10\n",
        "EPISODE = 1000\n",
        "TEST_EPISODE = 20\n",
        "\n",
        "\n",
        "last_accuracy = 0.0\n",
        "for episode in range(EPISODE):\n",
        "    #print(episode)\n",
        "\n",
        "    # init dataset\n",
        "    # sample_dataloader is to obtain previous samples for compare\n",
        "    # batch_dataloader is to batch samples for training\n",
        "    task = MiniImagenetTask(metatest_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "    sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "    batch_dataloader = get_mini_imagenet_data_loader(task,num_per_class=BATCH_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
        "\n",
        "    # sample datas\n",
        "    samples,sample_labels = sample_dataloader.__iter__().next() #25*3*84*84\n",
        "    batches,batch_labels = batch_dataloader.__iter__().next()\n",
        "\n",
        "    # calculate features\n",
        "    sample_features = feature_encoder(Variable(samples).cuda(GPU)) # 25*64*19*19\n",
        "    sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "    sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "    batch_features = feature_encoder(Variable(batches).cuda(GPU)) # 20x64*5*5\n",
        "\n",
        "    # calculate relations\n",
        "    # each batch sample link to every samples to calculate relations\n",
        "    # to form a 100x128 matrix for relation network\n",
        "    sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
        "    relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "    relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "    mse = nn.MSELoss().cuda(GPU)\n",
        "    one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1).cuda(GPU))\n",
        "    loss = mse(relations,one_hot_labels)\n",
        "\n",
        "\n",
        "    # training\n",
        "\n",
        "    feature_encoder.zero_grad()\n",
        "    relation_network.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(),0.5)\n",
        "    torch.nn.utils.clip_grad_norm_(relation_network.parameters(),0.5)\n",
        "\n",
        "    feature_encoder_optim.step()\n",
        "    relation_network_optim.step()\n",
        "\n",
        "    feature_encoder_scheduler.step(episode)\n",
        "    relation_network_scheduler.step(episode)\n",
        "\n",
        "\n",
        "    if (episode+1)%10 == 0:\n",
        "        print(loss.item())\n",
        "\n",
        "    if (episode+1)%1000 == 0:\n",
        "\n",
        "        # test\n",
        "        print(\"Testing...\")\n",
        "        accuracies = []\n",
        "        for i in range(TEST_EPISODE):\n",
        "            total_rewards = 0\n",
        "            counter = 0     #remove\n",
        "            task = MiniImagenetTask(metaval_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "            sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "            num_per_class = 5   #3\n",
        "            test_dataloader = get_mini_imagenet_data_loader(task,num_per_class=num_per_class,split=\"test\",shuffle=False)\n",
        "\n",
        "            sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
        "            for test_images,test_labels in test_dataloader:\n",
        "                batch_size = test_labels.shape[0]\n",
        "                # calculate features\n",
        "                sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
        "                sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "                sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "                test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
        "\n",
        "                # calculate relations\n",
        "                # each batch sample link to every samples to calculate relations\n",
        "                # to form a 100x128 matrix for relation network\n",
        "                sample_features_ext = sample_features.unsqueeze(0).repeat(batch_size,1,1,1,1)\n",
        "\n",
        "                test_features_ext = test_features.unsqueeze(0).repeat(1*CLASS_NUM,1,1,1,1)\n",
        "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
        "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "                _,predict_labels = torch.max(relations.data,1)\n",
        "\n",
        "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(batch_size)]\n",
        "\n",
        "                total_rewards += np.sum(rewards)\n",
        "                counter +=batch_size      #remove\n",
        "\n",
        "\n",
        "            accuracy = total_rewards/1.0/CLASS_NUM/BATCH_NUM_PER_CLASS\n",
        "            #accuracy = total_rewards/1.0/counter\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "        test_accuracy,h = mean_confidence_interval(accuracies)\n",
        "\n",
        "        print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
        "\n",
        "        if test_accuracy > last_accuracy:\n",
        "\n",
        "            # save networks\n",
        "            #torch.save(feature_encoder.state_dict(),str(\"miniimagenet/models/new/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "            #torch.save(relation_network.state_dict(),str(\"miniimagenet/models/new/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "\n",
        "            #print(\"save networks for episode:\",episode)\n",
        "            print(\"better network for episode:\" ,episode)\n",
        "            last_accuracy = test_accuracy\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "0.4025239050388336\n",
            "0.3106726109981537\n",
            "0.19906775653362274\n",
            "0.1611560434103012\n",
            "0.16055549681186676\n",
            "0.16202765703201294\n",
            "0.1602485328912735\n",
            "0.1562490612268448\n",
            "0.1555653214454651\n",
            "0.1553061604499817\n",
            "0.15415644645690918\n",
            "0.15851609408855438\n",
            "0.1580548733472824\n",
            "0.15302002429962158\n",
            "0.15341122448444366\n",
            "0.14315815269947052\n",
            "0.16280099749565125\n",
            "0.15430927276611328\n",
            "0.15675874054431915\n",
            "0.1559714376926422\n",
            "0.15085433423519135\n",
            "0.1762492060661316\n",
            "0.14946550130844116\n",
            "0.1577322781085968\n",
            "0.15807926654815674\n",
            "0.1546618491411209\n",
            "0.16239477694034576\n",
            "0.15663085877895355\n",
            "0.15672409534454346\n",
            "0.14125226438045502\n",
            "0.15252040326595306\n",
            "0.15330569446086884\n",
            "0.14578911662101746\n",
            "0.14023464918136597\n",
            "0.1574423611164093\n",
            "0.14931976795196533\n",
            "0.16374945640563965\n",
            "0.1512501835823059\n",
            "0.1528138667345047\n",
            "0.14303623139858246\n",
            "0.14503376185894012\n",
            "0.15204380452632904\n",
            "0.12047619372606277\n",
            "0.155124232172966\n",
            "0.13744790852069855\n",
            "0.15471439063549042\n",
            "0.1453837752342224\n",
            "0.14835834503173828\n",
            "0.15596531331539154\n",
            "0.145957350730896\n",
            "0.16085658967494965\n",
            "0.1275721788406372\n",
            "0.1428532749414444\n",
            "0.14344219863414764\n",
            "0.14239944517612457\n",
            "0.1408347487449646\n",
            "0.15058736503124237\n",
            "0.15043668448925018\n",
            "0.16504982113838196\n",
            "0.15444029867649078\n",
            "0.14705286920070648\n",
            "0.16681987047195435\n",
            "0.15844787657260895\n",
            "0.1606343388557434\n",
            "0.13538073003292084\n",
            "0.1695532500743866\n",
            "0.14686469733715057\n",
            "0.15861868858337402\n",
            "0.12447945028543472\n",
            "0.1450473964214325\n",
            "0.15959447622299194\n",
            "0.13950678706169128\n",
            "0.15926237404346466\n",
            "0.15516608953475952\n",
            "0.13163550198078156\n",
            "0.15942130982875824\n",
            "0.13976256549358368\n",
            "0.15940740704536438\n",
            "0.16536447405815125\n",
            "0.1633516103029251\n",
            "0.11852731555700302\n",
            "0.1392870545387268\n",
            "0.1602955162525177\n",
            "0.15214118361473083\n",
            "0.1307159811258316\n",
            "0.1667502224445343\n",
            "0.13332834839820862\n",
            "0.16942597925662994\n",
            "0.14789161086082458\n",
            "0.14648230373859406\n",
            "0.13795188069343567\n",
            "0.15468309819698334\n",
            "0.14760425686836243\n",
            "0.1503223329782486\n",
            "0.15656258165836334\n",
            "0.13853025436401367\n",
            "0.14308670163154602\n",
            "0.1440236121416092\n",
            "0.12924987077713013\n",
            "0.1570468693971634\n",
            "Testing...\n",
            "test accuracy: 0.36100000000000004 h: 0.03428782404816372\n",
            "better network for episode: 999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
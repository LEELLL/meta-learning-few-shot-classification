{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_miniImagenet_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirandou/ML-project/blob/master/baseline_miniImagenet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmx3jbv530kk",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHl-HKk_3Mug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmPXVo13jhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhsb8Cnf3lSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llgTurVolX7t",
        "colab_type": "code",
        "outputId": "4ed6a8df-4f56-4e12-e6b2-65ae3c8c5c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa-jE56wS-0V",
        "colab_type": "text"
      },
      "source": [
        "For Saghar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtErM4-bcDde",
        "colab_type": "code",
        "outputId": "a98efd68-6560-4426-aee9-d04dfbb61ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/ML project'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNUFhy1eTBOI",
        "colab_type": "text"
      },
      "source": [
        "For Others:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9349e57b-2c5b-48e5-ddab-cfbbeff318ff",
        "id": "hzifRS-_TEVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/drive/My Drive/ML project'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1i2V0Uhzl16puxTijLOIGlvFKhYU-RkZm/ML project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_x4IPkk_ZWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import Sampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz0rJ5ITqWrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mini_imagenet_folders():\n",
        "    train_folder = 'datas/miniImagenet/train'\n",
        "    test_folder = 'datas/miniImagenet/test'                ##val?\n",
        "    val_folder = 'datas/miniImagenet/val'\n",
        "\n",
        "    metatrain_folders = [os.path.join(train_folder, label) \\\n",
        "                for label in os.listdir(train_folder) \\\n",
        "                if os.path.isdir(os.path.join(train_folder, label)) \\\n",
        "                ]\n",
        "    metatest_folders = [os.path.join(test_folder, label) \\\n",
        "                for label in os.listdir(test_folder) \\\n",
        "                if os.path.isdir(os.path.join(test_folder, label)) \\\n",
        "                ]\n",
        "    metaval_folders = [os.path.join(val_folder, label) \\\n",
        "                for label in os.listdir(val_folder) \\\n",
        "                if os.path.isdir(os.path.join(val_folder, label)) \\\n",
        "                ]\n",
        "\n",
        "    random.seed(1)\n",
        "    random.shuffle(metatrain_folders)\n",
        "    random.shuffle(metatest_folders)\n",
        "    random.shuffle(metaval_folders)\n",
        "\n",
        "    return metatrain_folders,metatest_folders, metaval_folders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KX09XQKALfM",
        "colab_type": "code",
        "outputId": "39a3ef7d-33e0-461a-ac6b-ade26cd5abe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abolfazl-miniImagenet_train.ipynb  miniImagenet_train.ipynb\n",
            "Abolfazl-omniglot_test.ipynb       \u001b[0m\u001b[01;34momniglot\u001b[0m/\n",
            "\u001b[01;34mdatas\u001b[0m/                             omniglot_test.ipynb\n",
            "\u001b[01;34mminiimagenet\u001b[0m/                      omniglot_train.ipynb\n",
            "miniImagenet_test.ipynb            resnet_miniImagenet_train.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7M2Orp_xog",
        "colab_type": "code",
        "outputId": "edb12cf5-8317-4a9d-ab9a-1f81894b9915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 1: init data folders\n",
        "print(\"init data folders\")\n",
        "# init character folders for dataset construction\n",
        "metatrain_folders,metatest_folders,metaval_folders = mini_imagenet_folders()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init data folders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJeVI7wWAmSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import scipy as sp\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "FEATURE_DIM = 64\n",
        "RELATION_DIM = 8\n",
        "CLASS_NUM = 5\n",
        "SAMPLE_NUM_PER_CLASS = 5   #1\n",
        "BATCH_NUM_PER_CLASS = 10   #15\n",
        "EPISODE = 1000\n",
        "TEST_EPISODE = 20\n",
        "LEARNING_RATE = 0.001\n",
        "GPU = 0\n",
        "HIDDEN_UNIT = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH3-0uO3CzXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(3,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        #out = out.view(out.size(0),-1)\n",
        "        return out # 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQ5kfkvDHtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RelationNetwork(nn.Module):\n",
        "    \"\"\"docstring for RelationNetwork\"\"\"\n",
        "    def __init__(self,input_size,hidden_size):\n",
        "        super(RelationNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(64*2,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.fc1 = nn.Linear(input_size*3*3,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = torch.sigmoid(self.fc2(out))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8TP0r34aGCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        n = m.weight.size(1)\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        m.bias.data = torch.ones(m.bias.data.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYagIyND2BX",
        "colab_type": "code",
        "outputId": "2d988769-b756-4ec7-b4b9-71da9fa3f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Step 2: init neural networks\n",
        "print(\"init neural networks\")\n",
        "\n",
        "feature_encoder = CNNEncoder()\n",
        "relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
        "\n",
        "feature_encoder.apply(weights_init)\n",
        "relation_network.apply(weights_init)\n",
        "\n",
        "feature_encoder.cuda(GPU)\n",
        "relation_network.cuda(GPU)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelationNetwork(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuwctmD2q8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=LEARNING_RATE)\n",
        "feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
        "relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
        "relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhEQlGhyEOzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if os.path.exists(str(\"miniimagenet/models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "#    feature_encoder.load_state_dict(torch.load(str(\"miniimagenet/models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "#    print(\"load feature encoder success\")\n",
        "#if os.path.exists(str(\"miniimagenet/models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "#    relation_network.load_state_dict(torch.load(str(\"miniimagenet/models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "#    print(\"load relation network success\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y85slNVbDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_confidence_interval(data, confidence=0.95):\n",
        "    a = 1.0*np.array(data)\n",
        "    n = len(a)\n",
        "    m, se = np.mean(a), scipy.stats.sem(a)\n",
        "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
        "    return m,h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw9uNk3cFhrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Rotate(object):\n",
        "    def __init__(self, angle):\n",
        "        self.angle = angle\n",
        "    def __call__(self, x, mode=\"reflect\"):\n",
        "        x = x.rotate(self.angle)\n",
        "        return x\n",
        "\n",
        "class MiniImagenetTask(object):\n",
        "\n",
        "    def __init__(self, character_folders, num_classes, train_num,test_num):\n",
        "\n",
        "        self.character_folders = character_folders\n",
        "        self.num_classes = num_classes\n",
        "        self.train_num = train_num\n",
        "        self.test_num = test_num\n",
        "\n",
        "        class_folders = random.sample(self.character_folders,self.num_classes)\n",
        "        labels = np.array(range(len(class_folders)))\n",
        "        labels = dict(zip(class_folders, labels))\n",
        "        samples = dict()\n",
        "\n",
        "        self.train_roots = []\n",
        "        self.test_roots = []\n",
        "        for c in class_folders:\n",
        "\n",
        "            temp = [os.path.join(c, x) for x in os.listdir(c)]\n",
        "            samples[c] = random.sample(temp, len(temp))\n",
        "            random.shuffle(samples[c])\n",
        "\n",
        "            self.train_roots += samples[c][:train_num]\n",
        "            self.test_roots += samples[c][train_num:train_num+test_num]\n",
        "\n",
        "        self.train_labels = [labels[self.get_class(x)] for x in self.train_roots]\n",
        "        self.test_labels = [labels[self.get_class(x)] for x in self.test_roots]\n",
        "\n",
        "    def get_class(self, sample):\n",
        "        return os.path.join(*sample.split('/')[:-1])\n",
        "\n",
        "class FewShotDataset(Dataset):\n",
        "\n",
        "    def __init__(self, task, split='train', transform=None, target_transform=None):\n",
        "        self.transform = transform # Torch operations on the input image\n",
        "        self.target_transform = target_transform\n",
        "        self.task = task\n",
        "        self.split = split\n",
        "        self.image_roots = self.task.train_roots if self.split == 'train' else self.task.test_roots\n",
        "        self.labels = self.task.train_labels if self.split == 'train' else self.task.test_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_roots)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raise NotImplementedError(\"This is an abstract class. Subclass this class for your particular dataset.\")\n",
        "\n",
        "class MiniImagenet(FewShotDataset):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MiniImagenet, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_root = self.image_roots[idx]\n",
        "        image = Image.open(image_root)\n",
        "        image = image.convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class ClassBalancedSampler(Sampler):\n",
        "    ''' Samples 'num_inst' examples each from 'num_cl' pools\n",
        "        of examples of size 'num_per_class' '''\n",
        "\n",
        "    def __init__(self, num_cl, num_inst,shuffle=True):\n",
        "\n",
        "        self.num_cl = num_cl\n",
        "        self.num_inst = num_inst\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # return a single list of indices, assuming that items will be grouped by class\n",
        "        if self.shuffle:\n",
        "            batches = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)] for j in range(self.num_cl)]\n",
        "        else:\n",
        "            batches = [[i+j*self.num_inst for i in range(self.num_inst)] for j in range(self.num_cl)]\n",
        "        batches = [[batches[j][i] for j in range(self.num_cl)] for i in range(self.num_inst)]\n",
        "\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batches)\n",
        "            for sublist in batches:\n",
        "                   random.shuffle(sublist)\n",
        "        batches = [item for sublist in batches for item in sublist]\n",
        "        return iter(batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "class ClassBalancedSamplerOld(Sampler):\n",
        "    ''' Samples 'num_inst' examples each from 'num_cl' pools\n",
        "        of examples of size 'num_per_class' '''\n",
        "\n",
        "    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n",
        "        self.num_per_class = num_per_class\n",
        "        self.num_cl = num_cl\n",
        "        self.num_inst = num_inst\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # return a single list of indices, assuming that items will be grouped by class\n",
        "        if self.shuffle:\n",
        "            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
        "        else:\n",
        "            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
        "        batch = [item for sublist in batch for item in sublist]\n",
        "\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batch)\n",
        "        return iter(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "\n",
        "def get_mini_imagenet_data_loader(task, num_per_class=1, split='train',shuffle = False):\n",
        "    normalize = transforms.Normalize(mean=[0.92206, 0.92206, 0.92206], std=[0.08426, 0.08426, 0.08426])\n",
        "\n",
        "    dataset = MiniImagenet(task,split=split,transform=transforms.Compose([transforms.ToTensor(),normalize]))\n",
        "    if split == 'train':\n",
        "        sampler = ClassBalancedSamplerOld(num_per_class,task.num_classes, task.train_num,shuffle=shuffle)\n",
        "\n",
        "    else:\n",
        "        sampler = ClassBalancedSampler(task.num_classes, task.test_num,shuffle=shuffle)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=num_per_class*task.num_classes, sampler=sampler)\n",
        "    return loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCvlURcIHqV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EazfPJogFFkh",
        "colab_type": "code",
        "outputId": "3f93d8ed-f965-4317-eca9-18dacfd1b668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Step 3: build graph\n",
        "print(\"Training...\")\n",
        "TEST_EPISODE = 20\n",
        "last_accuracy = 0.0\n",
        "\n",
        "for episode in range(EPISODE):\n",
        "    #print(episode)\n",
        "\n",
        "    # init dataset\n",
        "    # sample_dataloader is to obtain previous samples for compare\n",
        "    # batch_dataloader is to batch samples for training\n",
        "    task = MiniImagenetTask(metatest_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "    sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "    batch_dataloader = get_mini_imagenet_data_loader(task,num_per_class=BATCH_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
        "\n",
        "    # sample datas\n",
        "    samples,sample_labels = sample_dataloader.__iter__().next() #25*3*84*84\n",
        "    batches,batch_labels = batch_dataloader.__iter__().next()\n",
        "\n",
        "    # calculate features\n",
        "    sample_features = feature_encoder(Variable(samples).cuda(GPU)) # 25*64*19*19\n",
        "    sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "    sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "    batch_features = feature_encoder(Variable(batches).cuda(GPU)) # 20x64*5*5\n",
        "\n",
        "    # calculate relations\n",
        "    # each batch sample link to every samples to calculate relations\n",
        "    # to form a 100x128 matrix for relation network\n",
        "    sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
        "    batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
        "    relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "    relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "    mse = nn.MSELoss().cuda(GPU)\n",
        "    one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1).cuda(GPU))\n",
        "    loss = mse(relations,one_hot_labels)\n",
        "\n",
        "\n",
        "    # training\n",
        "\n",
        "    feature_encoder.zero_grad()\n",
        "    relation_network.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(),0.5)\n",
        "    torch.nn.utils.clip_grad_norm_(relation_network.parameters(),0.5)\n",
        "\n",
        "    feature_encoder_optim.step()\n",
        "    relation_network_optim.step()\n",
        "\n",
        "    feature_encoder_scheduler.step(episode)\n",
        "    relation_network_scheduler.step(episode)\n",
        "\n",
        "\n",
        "    if (episode+1)%100 == 0:\n",
        "        print(loss.item())\n",
        "\n",
        "    if (episode+1)%1000 == 0:\n",
        "\n",
        "        # test\n",
        "        print(\"Testing...\")\n",
        "        accuracies = []\n",
        "        for i in range(TEST_EPISODE):\n",
        "            total_rewards = 0\n",
        "            counter = 0     #remove\n",
        "            task = MiniImagenetTask(metaval_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "            sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
        "            num_per_class = 5   #3\n",
        "            test_dataloader = get_mini_imagenet_data_loader(task,num_per_class=num_per_class,split=\"test\",shuffle=False)\n",
        "\n",
        "            sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
        "            for test_images,test_labels in test_dataloader:\n",
        "                batch_size = test_labels.shape[0]\n",
        "                # calculate features\n",
        "                sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
        "                sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,19,19)\n",
        "                sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "                test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
        "\n",
        "                # calculate relations\n",
        "                # each batch sample link to every samples to calculate relations\n",
        "                # to form a 100x128 matrix for relation network\n",
        "                sample_features_ext = sample_features.unsqueeze(0).repeat(batch_size,1,1,1,1)\n",
        "\n",
        "                test_features_ext = test_features.unsqueeze(0).repeat(1*CLASS_NUM,1,1,1,1)\n",
        "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
        "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
        "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "                _,predict_labels = torch.max(relations.data,1)\n",
        "\n",
        "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(batch_size)]\n",
        "\n",
        "                total_rewards += np.sum(rewards)\n",
        "                counter +=batch_size      #remove\n",
        "\n",
        "\n",
        "            accuracy = total_rewards/1.0/CLASS_NUM/BATCH_NUM_PER_CLASS\n",
        "            #accuracy = total_rewards/1.0/counter\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "        test_accuracy,h = mean_confidence_interval(accuracies)\n",
        "\n",
        "        print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
        "\n",
        "        if test_accuracy > last_accuracy:\n",
        "\n",
        "            # save networks\n",
        "            #torch.save(feature_encoder.state_dict(),str(\"miniimagenet/models/new/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "            #torch.save(relation_network.state_dict(),str(\"miniimagenet/models/new/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "\n",
        "            #print(\"save networks for episode:\",episode)\n",
        "            print(\"better network for episode:\" ,episode)\n",
        "            last_accuracy = test_accuracy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "0.1586916446685791\n",
            "0.14670328795909882\n",
            "0.14058363437652588\n",
            "0.1506078690290451\n",
            "0.14937527477741241\n",
            "0.10397420823574066\n",
            "0.11126196384429932\n",
            "0.12347830832004547\n",
            "0.12104904651641846\n",
            "0.13889151811599731\n",
            "Testing...\n",
            "test accuracy: 0.4010000000000001 h: 0.04468186467502009\n",
            "better network for episode: 999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}